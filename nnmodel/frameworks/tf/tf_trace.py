from nnmodel.core.trace import Tracepoint,Trace

class TFTracepoint(Tracepoint):
  def __init__(self, name, type, device, dt, t0=0, tensor_dims=None):
    super(TFTracepoint,self).__init__(name, type, device, dt)
    self.t0 = t0
    if tensor_dims is None:
      tensor_dims = []
    self.tensor_dims = tensor_dims
  def __str__(self):
    return '<TFTracepoint: name='+str(self.name)+' type='+str(self.type)+' device='+str(self.device)+' dt='+str(self.dt)+' t0='+str(self.t0)+' dims='+str(self.tensor_dims)+'>'

class TFTrace(Trace):
  pass

  def remove_generated_ops(self, native_model ):
    # Sometimes the operations that are generated by a session trace in TF are
    # not actually specified in the original TF graph. This can be for one of
    # two reasons:
    #   1) It's a _SOURCE or _SINK node. These are the sentinel nodes that TF
    #      inserts into a graph to do partial evaluation. (See the TF whitepaper
    #      section on partial evaluation for more info.)
    #   2) It's the result of a graph optimization. The primary one I've seen in
    #      the wild is the ...__cf__... ops. These are constant folding ops, the
    #      product of statically combining several scalar arithmetic operations.
    # Either way, we remove these ops. The first case is safe---the sentinel
    # nodes don't actually do any computation. The second case is unsafe, but we
    # have good reason to suspect that the amount of computation involved is
    # small: TF won't constant-fold tensors (as of the time of writing). They
    # are (rightly) worried about exploding size and optimization time. As a
    # result, eliminating these operations should have a negligible impact on
    # overall performance modeling accuracy. Their removal drastically
    # simplifies code using traces, as it is becomes a many-to-one mapping,
    # instead of a N-to-M mapping.
    model_ops = set([op.name for op in native_model.get_operations()])
    # Mark...
    for i,tracepoint in enumerate(self._tracepoints):
      if tracepoint.name not in model_ops:
        # NOTE: when logging is implemented, it might be good to note the
        #  removed operations at a debug level.
        self._tracepoints[i] = None
        self._len -= 1
        # FIXME: The following if statement was added because '_SOURCE' nodes would sometimes not appear on GPU graphs. It's unclear why this bug cropped up, so this fix was just fixing the symptom. Don't know if it fixed the underlying problem.
        if tracepoint.name in self._namemap:
          del self._namemap[tracepoint.name]
    # ...and compact
    self._tracepoints = filter(None, self._tracepoints)
